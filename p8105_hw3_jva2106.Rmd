---
title: "Homework 3"
author: "Jyoti Ankam"
date: "October 7, 2018"
output: github_document
---

```{r}
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_bw() + theme(legend.position = "bottom"))
```


Loading the tidyverse dataset and formatting the data to use appropriate variable names with a focus on the “Overall Health” topic and including only responses from “Excellent” to “Poor” while organizing responses as a factor taking levels from “Excellent” to “Poor”:

```{r}
library(tidyverse)

library(p8105.datasets)

data("brfss_smart2010")
brfss_smart_df = brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(topic == "Overall Health") %>% 
  select(-(class:question), -sample_size, -(confidence_limit_low:geo_location)) %>% 
  mutate(response = forcats::fct_relevel(response, c("Excellent", "Very good", "Good", "Fair", "Poor"))) 
 
brfss_smart_df %>% 
  filter(year == 2002) %>% 
  group_by(locationdesc) %>% 
  summarise(n = n())
 
brfss_smart_df %>% 
  group_by(locationabbr, year) %>% 
  summarise(n = n()) %>% 
  ggplot(aes(x = year, y = n, color = locationabbr)) +
  geom_line() +
  theme(legend.position = "left") +
  labs(
    title = "Spaghetti plot",
    x = "Year",
    y = "Number of observed locations",
    caption = "BRFSS data - 2010"
  )

brfss_smart_df %>% 
  filter(year %in% c(2002, 2006, 2010) & locationabbr == "NY") %>% 
  spread(key = response, value = data_value) %>% 
  janitor::clean_names() %>% 
  group_by(locationabbr, year) %>% 
  summarise(n = n(),
            mean = mean(excellent),
            sd = sd(excellent)) %>% 
  knitr::kable()
 

brfss_smart_df %>% 
  spread(key = response, value = data_value) %>% 
  janitor::clean_names() %>% 
  group_by(locationabbr, year) %>% 
  summarise(n = n(),
            mean_excellent = mean(excellent, na.rm = TRUE),
            mean_very_good = mean(very_good, na.rm = TRUE),
            mean_good = mean(good, na.rm = TRUE),
            mean_fair = mean(fair, na.rm = TRUE),
            mean_poor = mean(poor, na.rm = TRUE)) %>%
  gather(key = mean_name, value = mean_value, mean_excellent:mean_poor) %>% 
  ggplot(aes(x = year, y = mean_value, color = locationabbr)) +
  geom_line() +
  facet_grid(~mean_name)
  
```

```{r}

data("instacart")

```

How many aisles are there, and which aisles are the most items ordered from?

```{r}

instacart %>% 
  distinct(aisle_id) %>% 
  count()

instacart %>%
  group_by(aisle_id, aisle) %>% 
  summarise(number = n()) %>% 
  arrange(desc(number))

```

Make a plot that shows the number of items ordered in each aisle. Order aisles sensibly, and organize your plot so others can read it.

```{r}

instacart %>%
  group_by(aisle_id, aisle) %>% 
  summarise(number = n()) %>% 
  arrange(desc(number)) %>%
  mutate(aisle = tools::toTitleCase(aisle)) %>% 
  ggplot(aes(x = reorder(aisle, -number), y = number, fill = aisle)) +
  geom_col() +
  theme(axis.text.x = element_text(angle = 85, hjust = 1)) +
  theme(legend.position = "none") +
  theme(text = element_text(size = 8)) +
  labs(
    title = "Frequency distribution of aisle orders",
    x = "Aisle",
    y = "Number of orders",
    caption = "Instacart Data 2017"
  )

```
Make a table showing the most popular item aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”

```{r}
instacart %>% 
  select(product_name, aisle) %>% 
  filter(aisle == "baking ingredients" | aisle == "dog food care" | aisle == "packaged vegetables fruits") %>%
  group_by(aisle, product_name) %>% 
  summarise(number = n()) %>% 
  top_n(1, number) %>%
  arrange(desc(number)) %>% View
  
```

Make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week; format this table for human readers (i.e. produce a 2 x 7 table)

```{r}

instacart %>% 
  filter(product_name == "Pink Lady Apples" | product_name == "Coffee Ice Cream") %>% 
  group_by(order_dow, product_name) %>% 
  summarise()

```

